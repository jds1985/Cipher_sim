export const runtime = "nodejs";
// pages/api/chat.js
// Cipher OS â€” stable core + streaming

import { runCipherCore } from "../../cipher_core/core.js";
import { loadMemory, saveMemory } from "../../cipher_core/memory.js";

import { buildOSContext } from "../../cipher_os/runtime/osContext.js";
import { runOrchestrator } from "../../cipher_os/runtime/orchestrator.js";

import {
  loadMemoryNodes,
  loadSummary,
  saveSummary,
} from "../../cipher_os/memory/memoryGraph.js";

import { writebackFromTurn } from "../../cipher_os/memory/memoryWriteback.js";

// gravity
import { runMemoryDecay } from "../../cipher_os/memory/memoryDecay.js";

// extractor
import { extractMemoryFromTurn } from "../../cipher_os/memory/memoryExtractor.js";

// influence
import { buildMemoryInfluence } from "../../cipher_os/runtime/memoryInfluence.js";

function sseWrite(res, obj) {
  res.write(`data: ${JSON.stringify(obj)}\n\n`);
}

export default async function handler(req, res) {
  if (req.method !== "POST") {
    return res.status(405).json({ error: "Method not allowed" });
  }

  try {
    const message = req.body?.message?.trim() || "Hello";
    const wantStream = Boolean(req.body?.stream);

    const userId = "jim";
    const userName = "Jim";

    const trace = {
      log: (event, payload) => console.log(`[TRACE] ${event}`, payload ?? ""),
    };

    trace.log("request.received", { messageLength: message.length, wantStream });

    // â”€â”€ Load long-term memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const memoryData = await loadMemory(userId);
    const longTermHistory = memoryData?.history || [];
    trace.log("memory.loaded", { longTermTurns: longTermHistory.length });

    // â”€â”€ Load memory graph â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const nodes = await loadMemoryNodes(userId, 60);
    console.log("ğŸ”¥ MEMORY NODES LOADED:", nodes?.length);
    const summaryDoc = await loadSummary(userId);

    trace.log("memoryGraph.loaded", {
      nodes: nodes?.length || 0,
      hasSummary: Boolean(summaryDoc?.text),
    });

    // â”€â”€ Build OS context (NOW WITH WEIGHT ENGINE) â”€â”€â”€â”€â”€â”€â”€â”€
    const osContext = buildOSContext({
      requestId: Date.now().toString(),
      userId,
      userName,
      userMessage: message,
      uiHistory: [],
      longTermHistory,
      memoryNodes: nodes, // â­ IMPORTANT
    });

    osContext.memory.longTermSummary = summaryDoc?.text || "";

    trace.log("osContext.built", { requestId: osContext.requestId });

    // â”€â”€ Executive layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const executivePacket = await runCipherCore(
      {
        history: osContext.memory.mergedHistory,
        nodes: osContext.memory.nodes, // â­ use filtered nodes
        summary: osContext.memory.longTermSummary,
      },
      { userMessage: message, returnPacket: true }
    );

    trace.log("executive.complete", {
      hasSystemPrompt: Boolean(executivePacket?.systemPrompt),
    });

    // â­â­â­ APPLY INFLUENCE â­â­â­
    const influenceText = buildMemoryInfluence(osContext.memory.nodes);

    if (influenceText) {
      executivePacket.systemPrompt =
        (executivePacket.systemPrompt || "") + "\n" + influenceText;
    }

    trace.log("memory.influence", { applied: Boolean(influenceText) });

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // STREAM MODE
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (wantStream) {
      res.setHeader("Content-Type", "text/event-stream; charset=utf-8");
      res.setHeader("Cache-Control", "no-cache, no-transform");
      res.setHeader("Connection", "keep-alive");
      res.flushHeaders?.();

      const heartbeat = setInterval(() => {
        try {
          res.write(`: ping\n\n`);
        } catch {}
      }, 15000);

      let streamedText = "";

      sseWrite(res, { type: "meta", ok: true });

      const out = await runOrchestrator({
        osContext,
        executivePacket,
        trace,
        stream: true,
        onToken: (delta) => {
          streamedText += delta;
          sseWrite(res, { type: "delta", text: delta });
        },
      });

      sseWrite(res, {
        type: "done",
        reply: out?.reply || streamedText || "",
        model: out?.modelUsed?.model || null,
        provider: out?.modelUsed?.provider || null,
      });

      clearInterval(heartbeat);

      const finalReply = out?.reply || streamedText || "";

      await saveMemory(userId, { type: "interaction", role: "user", content: message });
      await saveMemory(userId, {
        type: "interaction",
        role: "assistant",
        content: finalReply,
      });

      trace.log("memory.saved", { userTurnSaved: true, assistantTurnSaved: true });

      const extracted = extractMemoryFromTurn(message, finalReply);

      await writebackFromTurn({
        userId,
        userText: message,
        assistantText: finalReply,
        extracted,
      });

      trace.log("memoryGraph.writeback", { completed: true });

      await runMemoryDecay(userId);
      trace.log("memory.decay.complete");

      const turns = (summaryDoc?.turns || 0) + 1;
      await saveSummary(userId, summaryDoc?.text || "", turns);
      trace.log("summary.updated", { turns });

      res.end();
      return;
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // NORMAL MODE
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const out = await runOrchestrator({
      osContext,
      executivePacket,
      trace,
    });

    const reply =
      typeof out === "string" ? out : out?.reply || out?.text || null;

    if (!reply) {
      console.error("âŒ Orchestrator returned no reply", out);
      return res.status(500).json({ error: "Model produced no reply" });
    }

    const model =
      out?.modelUsed?.model ||
      out?.model ||
      out?.engine ||
      null;

    await saveMemory(userId, { type: "interaction", role: "user", content: message });
    await saveMemory(userId, {
      type: "interaction",
      role: "assistant",
      content: reply,
    });

    trace.log("memory.saved", { userTurnSaved: true, assistantTurnSaved: true });

    const extracted = extractMemoryFromTurn(message, reply);

    await writebackFromTurn({
      userId,
      userText: message,
      assistantText: reply,
      extracted,
    });

    trace.log("memoryGraph.writeback", { completed: true });

    await runMemoryDecay(userId);
    trace.log("memory.decay.complete");

    const turns = (summaryDoc?.turns || 0) + 1;
    await saveSummary(userId, summaryDoc?.text || "", turns);
    trace.log("summary.updated", { turns });

    return res.status(200).json({ reply, model });
  } catch (err) {
    console.error("âŒ /api/chat fatal error:", err);
    return res.status(500).json({ error: err.message || "Chat failed" });
  }
}
